__NUXT_JSONP__("/en-us/conference/talk/207", (function(a,b){a.id=207;a.begin_time="2021-10-03T03:30:00Z";a.end_time="2021-10-03T04:00:00Z";a.is_remote=false;a.location="6-r2";a.youtube_id="e8XhXG-NiWk";a.title="Let's make your data pipeline robust with Great Expectations!";a.category="APPL";a.language="ENEN";a.python_level="INTERMEDIATE";a.recording_policy=true;a.abstract="Imagine you are a data engineer and in charge of a data pipeline. What do you think is the most important thing for the data pipeline? I think it is definitely the quality of data! However, the more complex your data pipeline becomes, the harder it is to maintain the data quality. For example, what if the format of some source data is changed without being noticed? What if some program update includes a bug? Such things cause data issues. It can take a long time to find the issues. Or even worse, your stakeholders may find the issues before you do!\r\n\r\nGreat Expectations helps you solve such problems. It is a Python-based open-source library for validating, documenting, and profiling your data. It allows you to define the shape of data, test data, and document the results. \r\n\r\nIn this talk, I will introduce you Great Expectations and share my experience with it. Let's make your data pipeline robust with Great Expectations!";a.detailed_description="* [Great Expectations] A Python-based open-source library for validating, documenting, and profiling your data.\r\n\r\n[Great Expectations]: https:\u002F\u002Fgreatexpectations.io";a.slide_link="https:\u002F\u002Fdocs.google.com\u002Fpresentation\u002Fd\u002F1ttwYJdFYLT9x87fusVAPBgcxZpEAE3g7AZ5eic34I7s\u002Fedit#slide=id.p";a.slido_embed_link="https:\u002F\u002Fapp.sli.do\u002Fevent\u002Fpib1ies7";a.hackmd_embed_link="https:\u002F\u002Fhackmd.io\u002F@pycontw\u002FHJRVK7qMt\u002Fedit";a.speakers=[{thumbnail_url:"https:\u002F\u002Ftw.pycon.org\u002Ftemp\u002Fstatic\u002Fimages\u002Fdefault_head.png",name:"Keisuke Nishitani",github_profile_url:b,twitter_profile_url:"https:\u002F\u002Ftwitter.com\u002Fkeinstn",facebook_profile_url:b,bio:"A data engineer and python programmer in Osaka, Japan. Working on a data pipeline built on Amazon Redshift, Amazon S3 and AWS Lambda. Interested in data workflow frameworks, data analysis and data visualization."}];a.event_type="talk";return {data:[{speechData:a}],fetch:{},mutations:[["setSpeechData",a]]}}({},"")));